{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8019269,"sourceType":"datasetVersion","datasetId":4725179}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install torch torchvision wandb\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T16:17:37.554025Z","iopub.execute_input":"2024-04-03T16:17:37.554389Z","iopub.status.idle":"2024-04-03T16:17:48.954301Z","shell.execute_reply.started":"2024-04-03T16:17:37.554359Z","shell.execute_reply":"2024-04-03T16:17:48.953117Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2+cpu)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.42.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Question 1 & Question 2**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, SubsetRandomSampler, random_split\nfrom torchvision.datasets import ImageFolder\nimport wandb\nfrom wandb.sdk.wandb_run import Run\nfrom tqdm import tqdm\n\n# Load the dataset\ntrain_data = ImageFolder('/kaggle/input/dataset1/inaturalist_12K/train', transform=train_transforms)\ntest_data = ImageFolder('/kaggle/input/dataset1/inaturalist_12K/val', transform=val_transforms)","metadata":{"execution":{"iopub.status.busy":"2024-04-04T17:20:35.352348Z","iopub.execute_input":"2024-04-04T17:20:35.353236Z","iopub.status.idle":"2024-04-04T17:20:38.127144Z","shell.execute_reply.started":"2024-04-04T17:20:35.353190Z","shell.execute_reply":"2024-04-04T17:20:38.126179Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Set up data transformations\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Count the number of samples in each class\nclass_counts = {}\nfor _, label in train_data:\n    if label not in class_counts:\n        class_counts[label] = 0\n    class_counts[label] += 1\n\n# Calculate the number of samples per class for validation set\nval_size_per_class = {label: int(count * 0.2) for label, count in class_counts.items()}\n\n# Initialize lists to hold indices for train and validation sets\ntrain_indices = []\nval_indices = []\n\n# Iterate through the dataset and assign samples to train or validation set\nfor idx, (_, label) in enumerate(train_data):\n    if val_size_per_class[label] > 0:\n        val_indices.append(idx)\n        val_size_per_class[label] -= 1\n    else:\n        train_indices.append(idx)\n\n# Create SubsetRandomSampler for train and validation sets\ntrain_sampler = SubsetRandomSampler(train_indices)\nval_sampler = SubsetRandomSampler(val_indices)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-04T17:20:39.959790Z","iopub.execute_input":"2024-04-04T17:20:39.960225Z","iopub.status.idle":"2024-04-04T17:24:56.829597Z","shell.execute_reply.started":"2024-04-04T17:20:39.960191Z","shell.execute_reply":"2024-04-04T17:24:56.828495Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"1\n2\n3\n4\n<torch.utils.data.sampler.SubsetRandomSampler object at 0x792de44ba380>\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the CNN model\nclass CNN(nn.Module):\n    def __init__(self, filters, activation, filter_organization, data_augmentation, batch_norm, dropout):\n        super(CNN, self).__init__()\n\n        self.conv_layers = nn.Sequential()\n        self.dense_layers = nn.Sequential()\n\n        # Add conv layers based on filter organization\n        if filter_organization == 'same':\n            num_filters = [filters] * 5  # Assuming 5 convolution layers\n        elif filter_organization == 'double':\n            num_filters = [filters * 2**i for i in range(5)]  # Doubling filters in each subsequent layer\n        else:\n            num_filters = [filters // 2**i for i in range(5)]  # Halving filters in each subsequent layer\n\n        in_channels = 3\n        for i, f in enumerate(num_filters):\n            print(f)\n            self.conv_layers.add_module(f\"conv_{i}\", nn.Conv2d(in_channels, f, kernel_size=3, padding=1))\n            if batch_norm:\n                self.conv_layers.add_module(f\"batch_norm_{i}\", nn.BatchNorm2d(f))\n            self.conv_layers.add_module(f\"{activation}_{i}\", getattr(nn, activation)())\n            self.conv_layers.add_module(f\"maxpool_{i}\", nn.MaxPool2d(kernel_size=2))\n            if data_augmentation and i == 0:\n                self.conv_layers.add_module(\"dropout\", nn.Dropout2d(p=dropout))  # Dropout only in the first layer\n            in_channels = f\n\n        self.dense_layers.add_module(\"flatten\", nn.Flatten())\n        self.dense_layers.add_module(\"dense\", nn.Linear(in_channels * 7 * 7, 512))\n        self.dense_layers.add_module(\"relu\", nn.ReLU())\n        self.output_layer = nn.Linear(512, len(train_data.classes))\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = self.dense_layers(x)\n        x = self.output_layer(x)\n        return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to calculate accuracy\ndef calculate_accuracy(outputs, labels):\n    _, predicted = torch.max(outputs, 1)\n    correct = (predicted == labels).sum().item()\n    accuracy = correct / labels.size(0)\n    return accuracy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\ndef training_model(optimizer, criterion, model, train_loader, val_loader):\n    epochs = 5\n    for epoch in range(epochs):\n        model.train()\n        training_loss = 0.0\n        train_accuracy = 0.0\n        pbar = tqdm(train_loader, total=len(train_loader))\n        for images, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            training_loss += loss.item()\n            train_accuracy += calculate_accuracy(outputs, labels)\n\n\n        model.eval()\n        val_loss = 0.0\n        val_accuracy = 0.0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                outputs = model(images)\n                val_loss += criterion(outputs, labels).item()\n                val_accuracy += calculate_accuracy(outputs, labels)\n\n        train_accuracy /= len(train_loader)\n        training_loss /= len(train_loader)\n        val_loss /= len(val_loader)\n        val_accuracy /= len(val_loader)\n        pbar.set_description(f'Epoch {epoch+1}/{epochs}, Train_Loss: {training_loss:.4f},  Train_Acc: {train_accuracy:.4f},  Val_Loss: {val_loss:.4f},  Val_Loss: {val_accuracy:.4f}')\n\n        wandb.log({\"epoch\": epoch+1, \"train_loss\": training_loss, \"val_loss\": val_loss, \"val_accuracy\": val_accuracy, \"train_accuracy\": train_accuracy})\n\n# Test the model\n# model.eval()\n# test_accuracy = 0.0\n# with torch.no_grad():\n#     for images, labels in test_loader:\n#         outputs = model(images)\n#         test_accuracy += calculate_accuracy(outputs, labels)\n\n# test_accuracy /= len(test_loader)\n# wandb.log({\"test_accuracy\": test_accuracy})\n\n# Save the model\n# torch.save(model.state_dict(), 'model.pth')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',  # Random search method\n    'metric': {'goal': 'maximize', 'name': 'val_accuracy'},  # Metric to optimize\n    'parameters': {\n        'batch_size': {32, 64},\n        'num_filters': {'values': [32, 64, 128]},\n        'activation': {'values': ['ReLU', 'GELU', 'SiLU', 'Mish']},\n        'filter_organization': {'values': ['same', 'double', 'halve']},\n        'data_augmentation': {'values': [True, False]},\n        'batch_norm': {'values': [True, False]},\n        'dropout': {'values': [0.2, 0.3]}\n    }\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nsweep_id = wandb.sweep(sweep_config, project='your-project-name', entity='your-entity-name')\n\n# Define your training function\ndef train():\n    # Use wandb.config to access hyperparameters in your training script\n    config = wandb.config\n    num_filters = config.num_filters\n    activation = config.activation\n    filter_organization = config.filter_organization\n    data_augmentation = config.data_augmentation\n    batch_norm = config.batch_norm\n    batch_size = config.batch_size\n    dropout = config.dropout\n    \n    # Your training code here\n    # Create an instance of the CNN model\n    model = CNN(num_filters, activation, filter_organization, data_augmentation, batch_norm, dropout)\n\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    \n    # Create DataLoader instances for train and validation sets using the samplers\n    train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n    val_loader = DataLoader(train_data, batch_size=batch_size, sampler=val_sampler)\n    \n    training_model(optimizer, criterion, model, train_loader, val_loader)\n\n    \n# Initialize Wandb run\nwandb.init()\n\n# Run the sweep\nwandb.agent(sweep_id, function=train)\n","metadata":{},"execution_count":null,"outputs":[]}]}