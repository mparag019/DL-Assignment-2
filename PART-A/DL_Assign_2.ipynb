{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8019269,"sourceType":"datasetVersion","datasetId":4725179}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:47:54.337213Z","iopub.execute_input":"2024-04-07T14:47:54.337784Z","iopub.status.idle":"2024-04-07T14:48:19.699254Z","shell.execute_reply.started":"2024-04-07T14:47:54.337752Z","shell.execute_reply":"2024-04-07T14:48:19.698344Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu118\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.16.2)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.4)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.42.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Question 1 & Question 2**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, SubsetRandomSampler, random_split, ConcatDataset\nfrom torchvision.datasets import ImageFolder\nimport wandb\nfrom wandb.sdk.wandb_run import Run\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n\nclasses = [\"Amphibia\", \"Animalia\", \"Arachnida\", \"Aves\", \"Fungi\", \"Insecta\", \"Mammalia\", \"Mollusca\", \"Plantae\", \"Reptilia\"]\n# Check if CUDA (GPU) is available, and set the device accordingly\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# Set up data transformations\ntrain_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transforms = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n# Load the dataset\ntrain_data = ImageFolder('/kaggle/input/dataset1/inaturalist_12K/train', transform=train_transforms)\ntest_data = ImageFolder('/kaggle/input/dataset1/inaturalist_12K/val', transform=test_transforms)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:38:09.815832Z","iopub.execute_input":"2024-04-07T16:38:09.816670Z","iopub.status.idle":"2024-04-07T16:38:14.272841Z","shell.execute_reply.started":"2024-04-07T16:38:09.816640Z","shell.execute_reply":"2024-04-07T16:38:14.271764Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:49:24.139336Z","iopub.execute_input":"2024-04-07T14:49:24.139957Z","iopub.status.idle":"2024-04-07T14:49:24.145087Z","shell.execute_reply.started":"2024-04-07T14:49:24.139925Z","shell.execute_reply":"2024-04-07T14:49:24.144042Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"True\ncuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# Count the number of samples in each class\nclass_counts = {}\npbar = tqdm(total=len(train_data))\nfor _, label in train_data:\n    if label not in class_counts:\n        class_counts[label] = 0\n    class_counts[label] += 1\n    pbar.set_postfix()\n    pbar.update(1)\n\npbar.close()\n\n# Calculate the number of samples per class for validation set\nval_size_per_class = {label: int(count * 0.2) for label, count in class_counts.items()}\n\n# Initialize lists to hold indices for train and validation sets\ntrain_indices = []\nval_indices = []\n\n# Iterate through the dataset and assign samples to train or validation set\npbar = tqdm(total=len(train_data))\nfor idx, (_, label) in enumerate(train_data):\n    if val_size_per_class[label] > 0:\n        val_indices.append(idx)\n        val_size_per_class[label] -= 1\n    else:\n        train_indices.append(idx)\n    pbar.set_postfix()\n    pbar.update(1)\n\npbar.close()\n\n# Create SubsetRandomSampler for train and validation sets\ntrain_sampler = SubsetRandomSampler(train_indices)\nval_sampler = SubsetRandomSampler(val_indices)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-04-07T14:49:26.732034Z","iopub.execute_input":"2024-04-07T14:49:26.733198Z","iopub.status.idle":"2024-04-07T14:54:32.239624Z","shell.execute_reply.started":"2024-04-07T14:49:26.733156Z","shell.execute_reply":"2024-04-07T14:54:32.238620Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d8b7469e5c9418582f02eea94c9ad76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6e72524614b4e6295eb6e35f1d5a739"}},"metadata":{}}]},{"cell_type":"code","source":"# print(len(train_loader.dataset))\n# print(len(val_loader.dataset))\n# print(len(val_indices))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_augmentation = True\n# batch_size = 32\n# if data_augmentation:\n#     additional_transforms = transforms.Compose([\n#         transforms.RandomHorizontalFlip(),\n#         transforms.RandomRotation(10),\n#         transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n#         transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n#     ])\n\n#     # Apply additional transformations to the new DataLoader\n#     original_dataset, transformed_dataset = apply_additional_transforms(train_loader, additional_transforms, batch_size)\n#     combined_dataset = ConcatDataset([original_dataset, transformed_dataset])\n\n#     # Create a new DataLoader using the combined dataset\n#     combined_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)\n\n# print(len(combined_loader))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the CNN model\nclass CNN(nn.Module):\n    def __init__(self, filters, activation, filter_organization, data_augmentation, batch_norm, dropout):\n        super(CNN, self).__init__()\n\n        self.conv_layers = nn.Sequential()\n        self.dense_layers = nn.Sequential()\n\n        # Add conv layers based on filter organization\n        if filter_organization == 'same':\n            num_filters = [filters] * 5  # Assuming 5 convolution layers\n        elif filter_organization == 'double':\n            num_filters = [filters * 2**i for i in range(5)]  # Doubling filters in each subsequent layer\n        else:\n            num_filters = [filters // 2**i for i in range(5)]  # Halving filters in each subsequent layer\n\n        in_channels = 3\n        for i, f in enumerate(num_filters):\n            self.conv_layers.add_module(f\"conv_{i}\", nn.Conv2d(in_channels, f, kernel_size=3, padding=1))\n            if batch_norm:\n                self.conv_layers.add_module(f\"batch_norm_{i}\", nn.BatchNorm2d(f))\n            self.conv_layers.add_module(f\"{activation}_{i}\", getattr(nn, activation)())\n            self.conv_layers.add_module(f\"maxpool_{i}\", nn.MaxPool2d(kernel_size=2))\n            self.conv_layers.add_module(\"dropout\", nn.Dropout2d(p=dropout)) \n            in_channels = f\n\n        self.dense_layers.add_module(\"flatten\", nn.Flatten())\n        self.dense_layers.add_module(\"dense\", nn.Linear(in_channels * 7 * 7, 512))\n        self.dense_layers.add_module(\"relu\", nn.ReLU())\n        self.output_layer = nn.Linear(512, len(train_data.classes))\n\n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = self.dense_layers(x)\n        x = self.output_layer(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:06:22.843715Z","iopub.execute_input":"2024-04-07T15:06:22.844608Z","iopub.status.idle":"2024-04-07T15:06:22.855946Z","shell.execute_reply.started":"2024-04-07T15:06:22.844574Z","shell.execute_reply":"2024-04-07T15:06:22.854980Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Function to calculate accuracy\ndef calculate_accuracy(outputs, labels):\n    _, predicted = torch.max(outputs, 1)\n    correct = (predicted == labels).sum().item()\n    accuracy = correct / labels.size(0)\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:06:23.353401Z","iopub.execute_input":"2024-04-07T15:06:23.354167Z","iopub.status.idle":"2024-04-07T15:06:23.359268Z","shell.execute_reply.started":"2024-04-07T15:06:23.354135Z","shell.execute_reply":"2024-04-07T15:06:23.358273Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Training loop\ndef training_model(epochs, optimizer, criterion, model, train_loader, val_loader):\n    for epoch in range(epochs):\n        model.train()\n        training_loss = 0.0\n        train_accuracy = 0.0\n        pbar = tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}')\n        for images, labels in train_loader:\n            optimizer.zero_grad()\n            images, labels = images.to(device), labels.to(device) \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            training_loss += loss.item()\n            train_accuracy += calculate_accuracy(outputs, labels)\n            pbar.set_postfix({'Train Loss': training_loss / (pbar.n + 1), 'Train Acc': train_accuracy / (pbar.n + 1)})\n            pbar.update(1)\n\n        pbar.close()\n\n\n        model.eval()\n        val_loss = 0.0\n        val_accuracy = 0.0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device) \n                outputs = model(images)\n                val_loss += criterion(outputs, labels).item()\n                val_accuracy += calculate_accuracy(outputs, labels)\n\n        train_accuracy /= len(train_loader)\n        training_loss /= len(train_loader)\n        val_loss /= len(val_loader)\n        val_accuracy /= len(val_loader)\n        print(f'Epoch {epoch+1}/{epochs}, Train_Loss: {training_loss:.4f},  Train_Acc: {train_accuracy:.4f},  Val_Loss: {val_loss:.4f},  Val_Accuracy: {val_accuracy:.4f}')\n        wandb.log({\"epoch\": epoch+1, \"train_loss\": training_loss, \"val_loss\": val_loss, \"val_accuracy\": val_accuracy, \"train_accuracy\": train_accuracy})\n    return model\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:06:23.915701Z","iopub.execute_input":"2024-04-07T15:06:23.916359Z","iopub.status.idle":"2024-04-07T15:06:23.926845Z","shell.execute_reply.started":"2024-04-07T15:06:23.916331Z","shell.execute_reply":"2024-04-07T15:06:23.925859Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# **Question 3**","metadata":{}},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes',  # Random search method\n    'metric': {'goal': 'maximize', 'name': 'val_accuracy'},  # Metric to optimize\n    'parameters': {\n        'epochs': {'values':[5, 10]},\n        'batch_size': {'values':[32, 64]},\n        'num_filters': {'values': [8, 16, 32, 64]},\n        'activation': {'values': ['ReLU', 'GELU', 'SiLU', 'Mish']},\n        'filter_organization': {'values': ['same', 'double', 'halve']},\n        'data_augmentation': {'values': [True, False]},\n        'batch_norm': {'values': [True, False]},\n        'dropout': {'values': [0.2, 0.3]}\n    }\n    \n}\n\n#Best Configuration\n# sweep_config = {\n#     'method': 'bayes',  # Random search method\n#     'metric': {'goal': 'maximize', 'name': 'val_accuracy'},  # Metric to optimize\n#     'parameters': {\n#         'epochs': {'values':[10]},\n#         'batch_size': {'values':[32]},\n#         'num_filters': {'values': [128]},\n#         'activation': {'values': ['GELU']},\n#         'filter_organization': {'values': ['same']},\n#         'data_augmentation': {'values': [False]},\n#         'batch_norm': {'values': [True]},\n#         'dropout': {'values': [0.3]}\n#     }\n    \n# }","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:06:27.720348Z","iopub.execute_input":"2024-04-07T15:06:27.720722Z","iopub.status.idle":"2024-04-07T15:06:27.727723Z","shell.execute_reply.started":"2024-04-07T15:06:27.720692Z","shell.execute_reply":"2024-04-07T15:06:27.726789Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def apply_additional_transforms(loader, additional_transforms, batch_size):\n    transformed_dataset = []\n    original_dataset = []\n    pbar = tqdm(total=len(loader))\n    for images, labels in loader:\n        images1 = additional_transforms(images)\n        for i in range(batch_size):\n            original_dataset.append((images[i], labels[i]))\n            transformed_dataset.append((images1[i], labels[i]))\n        pbar.set_postfix()\n        pbar.update(1)\n\n    pbar.close()\n    return original_dataset, transformed_dataset\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:06:29.778092Z","iopub.execute_input":"2024-04-07T15:06:29.778468Z","iopub.status.idle":"2024-04-07T15:06:29.785284Z","shell.execute_reply.started":"2024-04-07T15:06:29.778439Z","shell.execute_reply":"2024-04-07T15:06:29.784359Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def augment_data(data_augmentation, train_loader, batch_size):\n    if data_augmentation:\n        additional_transforms = transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n        ])\n\n        # Apply additional transformations to the new DataLoader\n        original_dataset, transformed_dataset = apply_additional_transforms(train_loader, additional_transforms, batch_size)\n        combined_dataset = ConcatDataset([original_dataset, transformed_dataset])\n\n        # Create a new DataLoader using the combined dataset\n        combined_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)\n    else:\n        combined_loader = train_loader\n    return combined_loader","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:06:30.250570Z","iopub.execute_input":"2024-04-07T15:06:30.250993Z","iopub.status.idle":"2024-04-07T15:06:30.257693Z","shell.execute_reply.started":"2024-04-07T15:06:30.250964Z","shell.execute_reply":"2024-04-07T15:06:30.256837Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def train_CNN(num_filters, activation, filter_organization, data_augmentation, batch_norm, dropout, batch_size, epochs):\n    # Create an instance of the CNN model\n    model = CNN(num_filters, activation, filter_organization, data_augmentation, batch_norm, dropout)\n    model.to(device)\n    \n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    # Create DataLoader instances for train and validation sets using the samplers\n    train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n    val_loader = DataLoader(train_data, batch_size=batch_size, sampler=val_sampler)\n\n    combined_loader = augment_data(data_augmentation, train_loader, batch_size)\n    \n    model = training_model(epochs, optimizer, criterion, model, combined_loader, val_loader)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:06:31.473711Z","iopub.execute_input":"2024-04-07T15:06:31.474379Z","iopub.status.idle":"2024-04-07T15:06:31.480827Z","shell.execute_reply.started":"2024-04-07T15:06:31.474349Z","shell.execute_reply":"2024-04-07T15:06:31.479859Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# wandb.login(key = \"1d2c93cf7ddd48a63114848b66796301171827b6\")\n# sweep_id = wandb.sweep(sweep_config, project='DL-Assignment-2')\n\n# # Define your training function\n# def train():\n    \n#     # Initialize Wandb run with custom run name\n#     with wandb.init() as run:\n        \n#         # Use wandb.config to access hyperparameters in your training script\n#         config = wandb.config\n#         num_filters = config['num_filters']\n#         activation = config['activation']\n#         filter_organization = config['filter_organization']\n#         data_augmentation = config['data_augmentation']\n#         batch_norm = config['batch_norm']\n#         batch_size = config['batch_size']\n#         epochs = config['epochs']\n#         dropout = config['dropout']\n#         # Generate a custom run name based on hyperparameters\n#         run_name = \"epochs_\" + str(epochs) + \"_nFilters_\" + str(num_filters) + \"_activation_\" + str(activation)+ \"_filterOrg_\" + str(filter_organization) + \"_batchSize_\" + str(batch_size)\n#         wandb.run.name = run_name\n        \n#         model = train_CNN(num_filters, activation, filter_organization, data_augmentation, batch_norm, dropout, batch_size, epochs)\n\n    \n        \n# # Run the sweep\n# wandb.agent(sweep_id, function=train, count=20)\n# wandb.finish()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-04-07T15:06:32.630072Z","iopub.execute_input":"2024-04-07T15:06:32.630435Z","iopub.status.idle":"2024-04-07T15:06:32.636033Z","shell.execute_reply.started":"2024-04-07T15:06:32.630405Z","shell.execute_reply":"2024-04-07T15:06:32.635105Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# **Question 4**","metadata":{}},{"cell_type":"code","source":"wandb.login(key = \"1d2c93cf7ddd48a63114848b66796301171827b6\")\nwith wandb.init( project='DL-Assignment-2') as run: \n    \n    #Best Configuration\n    epochs = 10\n    batch_size = 32\n    num_filters = 128\n    activation = 'GELU'\n    filter_organization = 'same'\n    data_augmentation = False\n    batch_norm = True \n    dropout = 0.3\n\n    run_name = \"epochs_\" + str(epochs) + \"_nFilters_\" + str(num_filters) + \"_activation_\" + str(activation)+ \"_filterOrg_\" + str(filter_organization) + \"_batchSize_\" + str(batch_size)\n    wandb.run.name = run_name\n    \n    model = train_CNN(num_filters, activation, filter_organization, data_augmentation, batch_norm, dropout, batch_size, epochs)\n\nwandb.finish()\n\n# Test the model\ntest_loader = DataLoader(test_data, batch_size=batch_size)\nmodel.eval()\n\ntest_accuracy = 0.0\nresults_list = []\npbar = tqdm(total=len(test_loader))\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device) \n        outputs = model(images)\n        images.to(\"cpu\")\n        labels.to(\"cpu\")\n        for i in range(len(images)):\n            image = images[i]\n            label = labels[i]\n            output = outputs[i].argmax(dim = 0)\n            if (label == output):\n                test_accuracy += 1\n            result_tuple = (image, label, output)\n            results_list.append(result_tuple)\n        pbar.set_postfix()\n        pbar.update(1)\n\npbar.close()\nwandb.login(key = \"1d2c93cf7ddd48a63114848b66796301171827b6\")\nwith wandb.init( project='DL-Assignment-2') as run:      \n    run_name = \"test_accuracy\"\n    wandb.run.name = run_name\n    test_accuracy /= len(test_data)\n    print(test_accuracy)\n    wandb.log({\"test_accuracy\": test_accuracy})\n\nwandb.finish()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T15:06:35.179452Z","iopub.execute_input":"2024-04-07T15:06:35.180075Z","iopub.status.idle":"2024-04-07T15:35:39.511878Z","shell.execute_reply.started":"2024-04-07T15:06:35.180042Z","shell.execute_reply":"2024-04-07T15:35:39.511165Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m047\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_150637-q7n7mf4d</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m047/DL-Assignment-2/runs/q7n7mf4d' target=\"_blank\">lucky-mountain-210</a></strong> to <a href='https://wandb.ai/cs23m047/DL-Assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m047/DL-Assignment-2' target=\"_blank\">https://wandb.ai/cs23m047/DL-Assignment-2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m047/DL-Assignment-2/runs/q7n7mf4d' target=\"_blank\">https://wandb.ai/cs23m047/DL-Assignment-2/runs/q7n7mf4d</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1/10:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afc16688f4fa4b8e8301a5ec05395cff"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/10, Train_Loss: 2.1886,  Train_Acc: 0.2221,  Val_Loss: 2.1086,  Val_Accuracy: 0.2729\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/10:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d84eb24b3b2469baa935423eb805791"}},"metadata":{}},{"name":"stdout","text":"Epoch 2/10, Train_Loss: 1.9936,  Train_Acc: 0.2920,  Val_Loss: 2.0160,  Val_Accuracy: 0.2920\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/10:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f37d80e103154491befeec05763cca68"}},"metadata":{}},{"name":"stdout","text":"Epoch 3/10, Train_Loss: 1.9293,  Train_Acc: 0.3114,  Val_Loss: 1.9727,  Val_Accuracy: 0.2929\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/10:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"075bd560c84441449c64d5381e5835e3"}},"metadata":{}},{"name":"stdout","text":"Epoch 4/10, Train_Loss: 1.8782,  Train_Acc: 0.3395,  Val_Loss: 1.9358,  Val_Accuracy: 0.3079\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/10:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48b580a5d98c47ce95e98caff78f691e"}},"metadata":{}},{"name":"stdout","text":"Epoch 5/10, Train_Loss: 1.8195,  Train_Acc: 0.3591,  Val_Loss: 1.8871,  Val_Accuracy: 0.3198\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6/10:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ab8726abf543e8abb6cb4583f3803a"}},"metadata":{}},{"name":"stdout","text":"Epoch 6/10, Train_Loss: 1.7772,  Train_Acc: 0.3735,  Val_Loss: 1.8580,  Val_Accuracy: 0.3485\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7/10:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ead68c02fd594f18a497d7c52101741e"}},"metadata":{}},{"name":"stdout","text":"Epoch 7/10, Train_Loss: 1.7073,  Train_Acc: 0.3971,  Val_Loss: 1.8890,  Val_Accuracy: 0.3337\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8/10:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a718635528341f889f5bcc363d0e50c"}},"metadata":{}},{"name":"stdout","text":"Epoch 8/10, Train_Loss: 1.6454,  Train_Acc: 0.4181,  Val_Loss: 1.8596,  Val_Accuracy: 0.3527\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9/10:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ad072a30ab94a65beb300040ac1ecac"}},"metadata":{}},{"name":"stdout","text":"Epoch 9/10, Train_Loss: 1.5780,  Train_Acc: 0.4487,  Val_Loss: 1.8560,  Val_Accuracy: 0.3575\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10/10:   0%|          | 0/250 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d34b7285cdc64b6f93f87cfab9d679b4"}},"metadata":{}},{"name":"stdout","text":"Epoch 10/10, Train_Loss: 1.4978,  Train_Acc: 0.4704,  Val_Loss: 1.9538,  Val_Accuracy: 0.3417\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.048 MB of 0.048 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▄▄▅▅▆▇▇█</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃▄▅▇▆██▇</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▁▂▁▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_accuracy</td><td>0.47037</td></tr><tr><td>train_loss</td><td>1.49777</td></tr><tr><td>val_accuracy</td><td>0.34167</td></tr><tr><td>val_loss</td><td>1.95378</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lucky-mountain-210</strong> at: <a href='https://wandb.ai/cs23m047/DL-Assignment-2/runs/q7n7mf4d' target=\"_blank\">https://wandb.ai/cs23m047/DL-Assignment-2/runs/q7n7mf4d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240407_150637-q7n7mf4d/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b5ff6afb92b41fd9d5ef6387e6cb87e"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_153442-94esdxsi</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m047/DL-Assignment-2/runs/94esdxsi' target=\"_blank\">lyric-cloud-211</a></strong> to <a href='https://wandb.ai/cs23m047/DL-Assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m047/DL-Assignment-2' target=\"_blank\">https://wandb.ai/cs23m047/DL-Assignment-2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m047/DL-Assignment-2/runs/94esdxsi' target=\"_blank\">https://wandb.ai/cs23m047/DL-Assignment-2/runs/94esdxsi</a>"},"metadata":{}},{"name":"stdout","text":"0.361\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.361</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lyric-cloud-211</strong> at: <a href='https://wandb.ai/cs23m047/DL-Assignment-2/runs/94esdxsi' target=\"_blank\">https://wandb.ai/cs23m047/DL-Assignment-2/runs/94esdxsi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240407_153442-94esdxsi/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"results_dict = {}\n\n# Organize tuples by label value in a dictionary\npbar = tqdm(total=len(results_list))\nfor image, label, predicted in results_list:\n    image = image.to(\"cpu\")\n    label = label.to(\"cpu\")\n    predicted = predicted.to(\"cpu\")\n    if label not in results_dict:\n        results_dict[label] = []\n    results_dict[label].append((image, label, predicted))\n    pbar.set_postfix()\n    pbar.update(1)\n\npbar.close()\n# a = 0\n# a = torch.tensor(a).to(device)\n\n# b = 1\n# b = torch.tensor(b).to(device)\n# print(len(results_dict[a]), len(results_dict[b]))\n\n# Create a list of three tuples for each label value\n\npbar = tqdm(total=len(results_dict))\nl = [0, 0 ,0, 0,0,0,0,0,0,0]\nlabels_done = []\nfiltered_results_list = []\ncount = 0\nfor label, tuples_list in results_dict.items():\n    if label.item() in labels_done and l[label.item()] < 3:\n#         print(tuples_list[0])\n        filtered_results_list.append(tuples_list)\n        l[label.item()] += 1\n    elif label.item() not in labels_done:\n        labels_done.append(label.item())\n        filtered_results_list.append(tuples_list)\n        l[label.item()] = 1\n\npbar.close()\n\nprint(len(filtered_results_list))\n\n\nwandb.login(key = \"1d2c93cf7ddd48a63114848b66796301171827b6\")\nwandb.init(project='DL-Assignment-2')\n\n# Create a figure and axis objects for plotting\nfig, axs = plt.subplots(10, 3, figsize=(12, 40))\n\n# Flatten the axis array to simplify indexing\naxs = axs.flatten()\n\nfor idx, i in enumerate(filtered_results_list):\n    # Assuming i[0] contains the image data in the correct format (e.g., a NumPy array)\n    image_data = i[0][0].numpy()  # Convert tensor to NumPy array\n\n    # Transpose image data if needed (e.g., for channels-first format)\n    image_transposed = np.transpose(image_data, (1, 2, 0))\n\n    # Display the image on the corresponding subplot\n    axs[idx].imshow(image_transposed)\n    axs[idx].axis('off')\n    axs[idx].set_title(f\"Label: {classes[i[0][1]]}\\nPredicted: {classes[i[0][2]]}\")\n\n# Adjust layout to prevent overlap of titles\nplt.tight_layout()\n\n# Log the plot to wandb as an image\nwandb.log({\"image_grid\": wandb.Image(plt)})\nplt.close()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:42:50.860903Z","iopub.execute_input":"2024-04-07T16:42:50.861797Z","iopub.status.idle":"2024-04-07T16:43:32.283818Z","shell.execute_reply.started":"2024-04-07T16:42:50.861766Z","shell.execute_reply":"2024-04-07T16:43:32.282864Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d7b9bb056d0483abe3933c35b18efca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cdb70224c8c4a1bbff1343f9f696ed8"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"30\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240407_164253-86pm4vzi</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs23m047/DL-Assignment-2/runs/86pm4vzi' target=\"_blank\">dandy-grass-212</a></strong> to <a href='https://wandb.ai/cs23m047/DL-Assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs23m047/DL-Assignment-2' target=\"_blank\">https://wandb.ai/cs23m047/DL-Assignment-2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs23m047/DL-Assignment-2/runs/86pm4vzi' target=\"_blank\">https://wandb.ai/cs23m047/DL-Assignment-2/runs/86pm4vzi</a>"},"metadata":{}}]},{"cell_type":"code","source":"# !jupyter notebook --ServerApp.iopub_msg_rate_limit=2000.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}